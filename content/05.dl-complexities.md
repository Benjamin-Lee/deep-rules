## Tip 3: Understand the complexities of training deep neural networks {#complexities}

Correctly training deep neural networks is a non-trivial process, as there are many different options and potential pitfalls at every stage.
To get good results, one must often train networks across a wide range of different hyperparameter settings.
Such training can be made more difficult by the demanding nature of these deep networks, which often require extensive time investments into tuning and computing infrastructure to achieve state-of-the-art performance [@doi:10.1109/JPROC.2017.2761740].
Furthermore, this experimentation is often noisy, necessitating increased repetition and exacerbating the organizational challenges inherent to deep learning.
On the whole, all code, random seeds, parameters, and results must be carefully corralled using general coding standards and best practices (for example, version control [@doi:10.1371/journal.pcbi.1004947] and continuous integration [@doi:10.1038/nbt.3780]) to be reproducible and interpretable [@doi:10.1371/journal.pcbi.1003285; @arxiv:1810.08055].
For application-based research, this organization is also fundamental to the efficient sharing of research work and the ability to keep models up to date as new data becomes available.

One specific reproducibility pitfall that is often missed in applying deep learning is the default use of non-deterministic algorithms by CUDA/CuDNN backends when using GPUs.
That is, the CUDA/CuDNN architectures that facilitate the parallelized computing that power state-of-the-art deep learning often use algorithms by default that produce different outcomes from iteration to iteration.
Therefore, achieving reproducibility in this context requires explicitly specifying the use of deterministic algorithms (which are typically available within deep learning libraries), which is distinct from the setting of random seeds that typically achieve reproducibility by controlling pseudorandom deterministic procedures such as shuffling and initialization [@url:https://docs.nvidia.com/deeplearning/sdk/cudnn-developer-guide/index.html#reproducibility].

Similar to the suggestions above about starting with simpler models, try to start with a relatively small network and then increase the size and complexity as needed.
This can help prevent practitioners from wasting significant time and resources on running highly complex models that feature numerous unresolved problems.
Again, beware of the choices made implicitly (that is, by default settings) by deep learning libraries (for example, selection of optimization algorithm), as these seemingly trivial specifics can have significant effects on model performance.
For example, adaptive methods often lead to faster convergence during training but may lead to worse generalization performance on independent datasets [@url:https://papers.nips.cc/paper/7003-the-marginal-value-of-adaptive-gradient-methods-in-machine-learning]).
These nuanced elements are easy to overlook, but it is critical to consider them carefully and to evaluate their potential impact.

In short, use smaller and simpler networks to enable faster prototyping and follow general software development best practices to maximize reproducibility.
