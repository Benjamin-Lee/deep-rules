## Tip 1: Concepts that apply to machine learning also apply to deep learning {#concepts}
Deep learning is a distinct subfield of machine learning, but it is still a subfield.
DL has proven to be an extremely powerful paradigm capable of outperforming “traditional” machine learning approaches in certain contexts, but it is not immune to the many limitations inherent to machine learning.
Many best practices for machine learning also apply to deep learning.
For instance, deep supervised learning models should be trained, tuned, and tested on non-overlapping datasets.
Similarly, to prevent overfitting, the data used for testing should be locked and only used one-time for evaluating the very final tuned model.
Those developing deep learning models should select data that are relevant to the problem at hand; non-salient data can hamper performance or lead to spurious conclusions.
Furthermore, investigators should begin by thoroughly inspecting their data.
When coupled with imprudence, data that is biased, skewed, or of low quality will produce models of dubious performance and limited generalizability.
Biases in testing data can also unduly influence measures of model performance.
For example, many conventional metrics for classification (e.g. area under the receiver operating characteristic curve or AUROC) have limited utility in cases of extreme class imbalance [@pmid:25738806].
As such, model performance should be evaluated with a carefully-picked panel of relevant metrics that make minimal assumptions about the composition of the testing data [@doi:10.1021/acs.molpharmaceut.7b00578].
Extreme cases warrant testing the robustness of the model and metrics on simulated data for which the ground truth is known.
Said simulations can be used to verify the correctness of the model’s implementation as well.
Like all computational methods, deep learning should be leveraged in a systematic manner that is reproducible and rigorously tested.
