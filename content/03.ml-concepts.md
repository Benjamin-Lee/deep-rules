## Tip 1: Successful deep learning applications require best practices for machine learning and model evaluation {#concepts}


In recent years, deep learning has proven to be an extremely powerful paradigm capable of outperforming "traditional" or "conventional" machine learning approaches.
The recent success behind applying deep learning is partly owed to the fact that DL algorithms are less dependent on manual feature extraction and are capable of achieving high predictive performance when operating on raw-data, such as images and text directly.
In contrast, traditional machine learning approaches often require manual feature extraction to produce acceptable results. 
However, the ability of deep learning to perform implicit feature extraction can be regarded as a double-edged sword.
For instance, those developing deep learning models not only need to ensure that the data contains information relevant to the problem at hand but is also free of systematic biases.
As deep learning models are capable of extracting and learning from complex patterns in a training dataset, DL models are also susceptible to systematic noise and non-salient information, which can not only hamper performance but also lead to spurious conclusions.

Since deep learning is still a subfield of machine learning, the majority of best practices for machine learning still apply to deep learning.
Like all computational methods, experiments involving deep learning should be conducted in a systematic manner and accompanied by reproducible instructions as well as rigorous model evaluation.
For instance, biases in testing data can unduly influence measures of model performance, and it may be difficult to identify confounders from the model directly.
Investigators should consider the extent to which the outcome of interest is likely to be predictable from the input data and begin by thoroughly inspecting the input data.
Suppose that there are robust heritability estimates for a phenotype that suggest that the genetic contribution is modest, but a deep learning model predicts the phenotype with very high accuracy.
The model may be capturing signal unrelated to genetic mechanisms underlying the phenotype.
In this case, a possible explanation is that people with similar genetic markers may have shared exposures.
This is something that researchers should probe before reporting unrealistically high prediction performances.
A similar situation can arise with tasks for which inter-rater reliability is modest but deep learning models produce very high prediction accuracies.
When coupled with imprudence, data that is confounded, biased, skewed, or of low quality will produce models of dubious performance and limited generalizability.

Using a test set more than once will lead to biased estimates of the generalization performance  [@arxiv:1811.12808; @doi:10.1162/089976698300017197].
Consequently, supervised deep learning models should be trained, tuned, and tested on non-overlapping datasets.
The data used for testing should be withheld during model tuning and refinement; test data should only be used one-time for evaluating the final model after all tuning steps are completed.
Also, many conventional metrics for classification (e.g., area under the receiver operating characteristic curve or AUROC) have limited utility in cases of extreme class imbalance [@pmid:25738806].
Model performance should be evaluated with a carefully-picked panel of relevant metrics that make minimal assumptions about the composition of the testing data [@doi:10.1021/acs.molpharmaceut.7b00578], with particular consideration given to metrics that are most directly applicable to the task at hand.

Extreme cases warrant testing the robustness of the model and metrics on simulated data for which the ground truth (i.e., the information to be predicted) is known.
Said simulations can be used to verify the technical correctness of a model's implementation as well.
