## Tip 2: Use traditional methods to establish performance baselines {#baselines}

Before diving into a fancy thousand-layer neural network, always implement at least a simple model to establish an adequate performance baseline. 
For example, researchers can build multinomial logistic regression or random forest models using the same software framework that is being used for DL and evaluate its classification performance. 
This approach will help researchers with assessing the complexity of the task at hand and debugging more complex DL architectures. 
The utility of these methods is evidenced by the recent development of hybrid models which combine DL and simpler models to improve robustness, interpretability, and confidence estimation [@arxiv:1803.04765; @arxiv:1805.11783].
Depending on the amount of available data and the type of tasks, DL models may not necessarily be the best performing one. 
As an illustration, the simple baseline models by Rajkomar et al. [@doi:10.1038/s41746-018-0029-1] achieved performance comparable with that of DL in a number of clinical prediction tasks using electronic health records, which may be a surprise to many. 

It is worth noting that many conventional machine learning methods (e.g., support vector machines, random forests) require parameter tuning. 
Instead of assuming that DL is better than other machine learning methods, researchers should investigate whether the baseline models are rigorously fine-tuned. 
The performance comparison among DL models and many other ML approaches is informative only when the models are fairly compared.
